# Extensive Reading List ðŸ“š

## NLP

* BARTSCORE: Evaluating Generated Text as Text Generation (2021/06) [[BARTSCORE](https://arxiv.org/abs/2106.11520), [code](https://github.com/neulab/BARTScore)]
* reStructured Pre-training (2022/06) [[pdf](https://arxiv.org/pdf/2206.11147.pdf), [code](https://github.com/ExpressAI/reStructured-Pretraining)]
* Examining Scaling and Transfer of Language Model Architectures for Machine Translation (2022/02) [[pdf](https://arxiv.org/abs/2202.00528), code]
* DeltaLM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders (2021/06)[[DeltaLM](https://arxiv.org/abs/2106.13736), [code](https://github.com/microsoft/unilm/tree/master/deltalm)]
* Towards Efficient NLP: A Standard Evaluation and A Strong Baseline (2021/11) [[ElasticBERT](https://arxiv.org/abs/2110.07038), [code](https://github.com/fastnlp/ElasticBERT)]

## CV
* Pretraining is All You Need for Image-to-Image Translation (2022/05) [[PITI](https://arxiv.org/abs/2205.12952), [blog](https://tengfei-wang.github.io/PITI/index.html)]
