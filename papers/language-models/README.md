# Language Model and Text Generation ðŸ“š

## Pre-training Language Models

* BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (2019/10, ACL) [[BART](https://arxiv.org/pdf/1910.13461.pdf)]
* Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (2019/10) [[T5](https://arxiv.org/abs/1910.10683), [code](https://github.com/google-research/text-to-text-transfer-transformer)]


## Text Generation

* A Contrastive Framework for Neural Text Generation (2022/02) [[SimCTG](https://arxiv.org/pdf/2202.06417.pdf) [code](https://github.com/yxuansu/SimCTG)]
* CONT: Contrastive Neural Text Generation (2022/05) [[CoNT](https://arxiv.org/pdf/2205.14690.pdf), [code](https://github.com/Shark-NLP/CoNT)]
